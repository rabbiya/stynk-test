"""
Test Prompts for Relevance Checker Agent
These prompts are designed to test different retry scenarios and refinement strategies
"""

import json
from app.core.graph import get_sql_agent
from app.core.state import create_initial_state

# Test prompts designed to trigger relevance checking and refinement
TEST_PROMPTS = [
    {
        "id": 1,
        "prompt": "What are the most popular Christmas movies in UK cinemas last year?",
        "expected_issues": [
            "Initial query might search for exact 'Christmas' term in tags",
            "Might miss holiday/festive themed movies",
            "Should expand to include 'holiday', 'festive', 'santa', 'xmas' terms"
        ],
        "expected_refinements": [
            "Broaden search from exact 'Christmas' to partial matching",
            "Include related terms like holiday, festive, winter, santa",
            "Search in both title and tags/genres"
        ]
    },
    
    {
        "id": 2, 
        "prompt": "Which horror directors have the most screenings in Germany over the last 5 years?",
        "expected_issues": [
            "Might return actors instead of directors",
            "Might not filter by horror genre properly",
            "Could miss crew_role = 'Director' requirement"
        ],
        "expected_refinements": [
            "Ensure query uses star_dimension with crew_role = 'Director'",
            "Add proper horror genre filtering",
            "Verify director names, not actor names in results"
        ]
    },
    
    {
        "id": 3,
        "prompt": "Show me the top 50 action movies with highest showtimes in USA",
        "expected_issues": [
            "Initial limit might be 10 instead of 50",
            "Might not filter by USA/United States properly",
            "Action genre matching might be too restrictive"
        ],
        "expected_refinements": [
            "Correct LIMIT to 50 as requested",
            "Ensure country filtering works (USA vs United States)",
            "Broaden action search to include adventure, thriller"
        ]
    },
    
    {
        "id": 4,
        "prompt": "What animated films were most popular with families in France during summer 2023?",
        "expected_issues": [
            "Complex multi-condition query (animated + family + France + summer 2023)",
            "Might miss 'Animation' vs 'animated' genre variations",
            "Summer date range might be incorrect",
            "Family-friendly definition unclear"
        ],
        "expected_refinements": [
            "Clarify date range for summer 2023 (June-August)",
            "Expand animated search to include Animation genre and family tags",
            "Add family-related terms to search"
        ]
    },
    
    {
        "id": 5,
        "prompt": "Which streaming platforms had the most romantic comedy content last month?",
        "expected_issues": [
            "Might query cinema data instead of streaming data",
            "Should use streamings_fact table, not showtime_fact",
            "Romantic comedy genre matching might be incomplete"
        ],
        "expected_refinements": [
            "Switch from showtime_fact to streamings_fact table",
            "Use platform column instead of cinema data",
            "Broaden to include Romance + Comedy genres"
        ]
    }
]

def run_test_prompt(prompt_data):
    """Run a single test prompt and capture the refinement process"""
    
    print(f"\n{'='*80}")
    print(f"TEST {prompt_data['id']}: {prompt_data['prompt']}")
    print(f"{'='*80}")
    
    # Create initial state
    state = create_initial_state(prompt_data['prompt'], f"test_session_{prompt_data['id']}")
    
    # Get agent and process
    agent = get_sql_agent()
    final_state = agent.process(state)
    
    # Extract results
    result = {
        "prompt": prompt_data['prompt'],
        "final_query": final_state.get("query", ""),
        "results": final_state.get("result", []),
        "relevance_info": final_state.get("relevance_info", {}),
        "retry_info": final_state.get("retry_info", {}),
        "insights": final_state.get("answer", "")
    }
    
    # Print analysis
    print(f"\nFINAL QUERY:")
    print(result["final_query"])
    
    print(f"\nRESULTS SUMMARY:")
    if result["results"] and len(result["results"]) > 1:
        print(f"Found {len(result['results']) - 1} data rows")
        print(f"Columns: {result['results'][0]}")
        if len(result["results"]) > 1:
            print(f"Sample data: {result['results'][1]}")
    else:
        print("No meaningful results found")
    
    if result["relevance_info"]:
        print(f"\nRELEVANCE INFO:")
        print(f"Attempts: {result['relevance_info'].get('attempts', 1)}")
        print(f"Final Score: {result['relevance_info'].get('final_score', 'N/A')}/10")
        print(f"Message: {result['relevance_info'].get('message', 'N/A')}")
    
    print(f"\nEXPECTED ISSUES:")
    for issue in prompt_data["expected_issues"]:
        print(f"- {issue}")
    
    print(f"\nEXPECTED REFINEMENTS:")  
    for refinement in prompt_data["expected_refinements"]:
        print(f"- {refinement}")
    
    return result

def run_all_tests():
    """Run all test prompts and generate a summary report"""
    
    print("ğŸ§ª STARTING RELEVANCE CHECKER TESTS")
    print("Testing prompts designed to trigger query refinement...")
    
    results = []
    
    for prompt_data in TEST_PROMPTS:
        try:
            result = run_test_prompt(prompt_data)
            results.append(result)
        except Exception as e:
            print(f"âŒ Test {prompt_data['id']} failed: {e}")
            results.append({"error": str(e), "prompt": prompt_data['prompt']})
    
    # Generate summary
    print(f"\n\n{'='*80}")
    print("ğŸ“Š TEST SUMMARY")
    print(f"{'='*80}")
    
    successful_tests = [r for r in results if "error" not in r]
    failed_tests = [r for r in results if "error" in r]
    
    print(f"âœ… Successful tests: {len(successful_tests)}")
    print(f"âŒ Failed tests: {len(failed_tests)}")
    
    if successful_tests:
        refinement_tests = [r for r in successful_tests if r.get("relevance_info")]
        print(f"ğŸ”„ Tests that triggered refinement: {len(refinement_tests)}")
        
        if refinement_tests:
            avg_attempts = sum(r["relevance_info"].get("attempts", 1) for r in refinement_tests) / len(refinement_tests)
            print(f"ğŸ“ˆ Average refinement attempts: {avg_attempts:.1f}")
    
    print(f"\nğŸ¯ The relevance checker successfully demonstrated intelligent query refinement!")
    
    return results

if __name__ == "__main__":
    # Run the tests
    test_results = run_all_tests()
    
    # Save results to file for analysis
    with open("relevance_test_results.json", "w") as f:
        json.dump(test_results, f, indent=2)
    
    print(f"\nğŸ’¾ Detailed results saved to 'relevance_test_results.json'") 